{
 "metadata": {
  "name": "",
  "signature": "sha256:90ff6b7c5110282def2a23b965c7334c9e0fa15933700fb543e769ffdfaa08d6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "\n",
      "import collections\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### File Snippets"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "#### columns_metadata.csv\n",
      "column_num\tdonor_id\tdonor_name\tage\tgender\tstructure_id\tstructure_acronym\tstructure_name\n",
      "1\t13058\tH376.IIA.51\t8 pcw\tM\t10361\tAMY\tamygdaloid complex\n",
      "2\t13058\tH376.IIA.51\t8 pcw\tM\t10552\tCGE\tcaudal ganglionic eminence\n",
      "3\t13058\tH376.IIA.51\t8 pcw\tM\t10173\tDFC\tdorsolateral prefrontal cortex\n",
      "4\t13058\tH376.IIA.51\t8 pcw\tM\t10391\tDTH\tdorsal thalamus\n",
      "\n",
      "\n",
      "#### rows_metadata.csv\n",
      "row_num\tgene_id\tensembl_gene_id\tgene_symbol\tentrez_id\n",
      "1\t9633\tENSG00000101337\tTM9SF4\t9777\n",
      "2\t22692\tENSG00000114650\tSCAP\t22937\n",
      "3\t22952\tENSG00000113194\tFAF2\t23197\n",
      "4\t34497\tENSG00000150401\tDCUN1D2\t55208"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "### BrainCloud GEO file\n",
      "http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE30272\n",
      "\n",
      "\n",
      "### About the format\n",
      "http://www.ncbi.nlm.nih.gov/geo/info/soft.html\n",
      "\n",
      "### Reading the NCBI's GEO microarray SOFT files in R/BioConductor\n",
      "http://www2.warwick.ac.uk/fac/sci/moac/people/students/peter_cock/r/geo/\n",
      "\n",
      "### Biopython\n",
      "http://biopython.org/DIST/docs/tutorial/Tutorial.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Design"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Read expression matrix HEADER (donor_id) and FIRST COLUMN (probeID) only\n",
      "1. The outline is the following: probeID --> [via soft family] --> HGNC --> [via biomart] --> Ensembl\n",
      "    1. Map probeID using .annot file\n",
      "        - write out a row file\n",
      "\n",
      "3. Read series_matrix. Extract the following information INTO DICT/collections:\n",
      "    1. Read only lines that starts with \"!Sample_\"\n",
      "    2. donor_id --> !Sample_title: \"HB_18_34\"\n",
      "    3. structure_acronym --> !Sample_source_name_ch1\t\"Postmortem dorsolateral prefrontal cortex (DLPFC BA 46/9)\"\n",
      "    4. stage --> DUMMY. Convert later!\n",
      "    4. age --> !Sample_characteristics_ch1\t\"age: -0.498630137\"\n",
      "    5. gender --> !Sample_characteristics_ch1\t\"Sex: F\"\n",
      "    - write out column file\n",
      "\n",
      "\n",
      "*Q: how to treat donor_id with UNDERSCORE (_)? Needs conversion?\n",
      "\n",
      "### Main purpose of this notebook script\n",
      "The main purpose is to write out \n",
      "- columns_metadata.csv\n",
      "- rows_metadata.csv. \n",
      "- (The matrix file can be read be R - no need to modify it)\n",
      "\n",
      "\n",
      "### Inside R\n",
      "1. Read *_metadata.csv, matrix file\n",
      "2. Dicretize the age\n",
      "2. Perform median calculation\n",
      "\n",
      "(use tidyr separate() or extract()?)\n",
      "\n",
      "    \n",
      "3. Convert header of file into the following format per field:\n",
      "- paste(donor_id, structure_acronym, stage, age, gender, sep=\"_\")\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### NOTES\n",
      "\n",
      "By manual inspection I found that the \"GI = GenBank identifier\" would be the best option to map from.\n",
      "Also the \"Gene ID = Entrez Gene identifier\" look ok.\n",
      "The following are considered BAD MAPPING IDs (from manual inspection)\n",
      "- UniGene ID (totally empty?)\n",
      "-\n",
      "\n",
      "Mapping results:\n",
      "- Mapping via \"probeID-->HGNC-->ENSG\" only gave 1819 probeIDs mapped to ENSG\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Script"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_annot = \"/Users/pascaltimshel/Dropbox/0_projects/p_EAv2/data_BrainCloud/mapping/GPL4611.annot\"\n",
      "\n",
      "#file_biomart = \"/Users/pascaltimshel/Dropbox/0_Projects/p_snpsnap/data/misc/biomart_download-2015-02-26-snpsnap_production_v2-ensembl-release_GRCh37.p13_processed-GENCODE.chrosome_clean.unique-ENSG_ID.csv\"\n",
      "file_biomart = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/mapping/biomart-download_release_78_UniGene_ID_03-09-2015.csv\"\n",
      "\n",
      "#file_expr_matrix = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/GSE30272_ExprsMtxCleanedN269_31SVN.txt\"\n",
      "file_expr_matrix = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/GSE30272_ExprsMtxCleanedN269_31SVN.correct_line_breaks.txt\"\n",
      "\n",
      "file_series_matrix = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/GSE30272_series_matrix.txt\"\n",
      "file_series_matrix_sample = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/GSE30272_series_matrix.Sample.txt\"\n",
      "\n",
      "\n",
      "#file_soft_family = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/GEO_formats/GSE30272_family.soft\"\n",
      "file_soft_family_platform_table = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/GEO_formats/GSE30272_family.soft.platform_table.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Write row file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step1: dict_map_mediatorID2ENSG [.biomart]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict_map_mediatorID2ENSG = {}\n",
      "non_unique_maps = {}\n",
      "\n",
      "with open(file_biomart, 'r') as f:\n",
      "    lines = f.readlines()\n",
      "    for line_no, line in enumerate(lines):\n",
      "        fields = line.split(\",\")\n",
      "        ENSG = fields[0]\n",
      "        #HGNC_symbol = fields[6]\n",
      "        mediatorID = fields[1]\n",
      "        \n",
      "        if mediatorID: # check that the field is non-empty\n",
      "            if not mediatorID in dict_map_mediatorID2ENSG:\n",
      "                dict_map_mediatorID2ENSG[mediatorID] = ENSG\n",
      "            else:\n",
      "                if not dict_map_mediatorID2ENSG[mediatorID] == ENSG: # Pascal suffers from being paranoid - and he knows it!\n",
      "                    ### NOTE: WE ONLY KEEP THE FIRST OF THE MAPPINGS. The following mappings are NOT saved\n",
      "                    #print \"non-unique mapping detected\"\n",
      "                    non_unique_maps[mediatorID] = ENSG\n",
      "                    \n",
      "print \"number of non-unique mappings: {}\".format(len(non_unique_maps))\n",
      "print \"mapped {} mediatorID to ENSG\".format(len(dict_map_mediatorID2ENSG))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of non-unique mappings: 2095\n",
        "mapped 44623 mediatorID to ENSG\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step2: dict_map_probeID2mediatorID"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict_map_probeID2mediatorID = {}\n",
      "set_empty_mediatorID = set()\n",
      "\n",
      "# REMEMBER: the file \"file_soft_family_platform_table\" should be in \"unix\" format (not mac format line endings)\n",
      "#ID\tOligoID\tSEQUENCE\tGB_ACC\tStrand\tGene_Symbol\tGene_Title\tEntrez_Gene_ID\tUniGene_Cluster_ID\tFeb2012_Blast_Cutoffs\tSPOT_ID\n",
      "#HEEBO-001-CTRL1F4\thCP000124\tCACTTGGTCCTGCGCTTGAGGGGGGGTGTCTAAGTTTCCCCTTTTAAGGTTTCAACAAATTTCATTGCAC\tNM_021009.5\t+\tUBC\tubiquitin C\t7316\tHs.520348\t100/100_MULTIPLE_REFSEQ\n",
      "\n",
      "with open(file_soft_family_platform_table, 'r') as f:\n",
      "    lines = f.readlines()[1:] # skip header\n",
      "    print len(lines)\n",
      "    for line_no, line in enumerate(lines):\n",
      "        fields = line.split(\"\\t\")\n",
      "        \n",
      "        probeID = fields[0]\n",
      "        mediatorID = fields[8]\n",
      "        if not mediatorID == \"\":\n",
      "            if not probeID in dict_map_probeID2mediatorID: # we have a newcomer! welcome to the dict!\n",
      "                dict_map_probeID2mediatorID[probeID] = mediatorID\n",
      "            else:\n",
      "                if not (dict_map_probeID2mediatorID[probeID] == mediatorID): # lets make sure that the mapping are consistent. Warn...\n",
      "                    print \"line_no = {} | The XXX file does not agree about the mapping\".format(line_no)\n",
      "        else:\n",
      "            set_empty_mediatorID.add(probeID)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "49152\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"len(dict_map_probeID2mediatorID)\", len(dict_map_probeID2mediatorID) # 38871  \n",
      "print \"len(set_empty_mediatorID)\", len(set_empty_mediatorID) # 10281  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "len(dict_map_probeID2mediatorID) 38871\n",
        "len(set_empty_mediatorID) 10281\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in dict_map_probeID2mediatorID.items():\n",
      "    print \"{}|{}\".format(k,v)\n",
      "    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HEEBO-074-HCC74C11|Hs.307015\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step3: combine mapping: dict_map_probeID2ENSG"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict_map_probeID2ENSG = {}\n",
      "set_probe_mapped = set()\n",
      "set_probe_unmapped = set()\n",
      "\n",
      "for probeID in dict_map_probeID2mediatorID:\n",
      "    mediatorID = dict_map_probeID2mediatorID[probeID]\n",
      "    if mediatorID in dict_map_mediatorID2ENSG:\n",
      "        ENSG = dict_map_mediatorID2ENSG[mediatorID]\n",
      "        dict_map_probeID2ENSG[probeID] = ENSG\n",
      "        set_probe_mapped.add(probeID)\n",
      "    else:\n",
      "        set_probe_unmapped.add(probeID)\n",
      "        \n",
      "print \"Mapped probes: {}\".format(len(set_probe_mapped))\n",
      "print \"Mapped unprobes: {}\".format(len(set_probe_unmapped))\n",
      "print \"number of unique ensembl IDs: {}\".format( len( set(dict_map_probeID2ENSG.values() ) ) ) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mapped probes: 30076\n",
        "Mapped unprobes: 8795\n",
        "number of unique ensembl IDs: 16519\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step3: WRITE EXPRESSION MATRIX + ROWS METADATA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_rows_metadata = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/processed_data/rows_metadata.csv\"\n",
      "file_rows_metadata_unmapped = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/processed_data/rows_metadata_unmapped.csv\"\n",
      "file_expression_matrix = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/processed_data/expression_matrix.csv\"\n",
      "\n",
      "set_probe_mapped = set()\n",
      "set_probe_unmapped = set()\n",
      "\n",
      "f_row_metadata = open(file_rows_metadata, 'w')\n",
      "f_row_metadata_unmapped = open(file_rows_metadata_unmapped, 'w')\n",
      "f_expression_matrix = open(file_expression_matrix, 'w')\n",
      "\n",
      "with open(file_expr_matrix, 'r') as f:\n",
      "    lines = f.readlines()[1:] # skipping header!\n",
      "    for line_no, line in enumerate(lines):\n",
      "        \n",
      "        ### TESTING/DEBUGGING\n",
      "        #if line_no == 10: break\n",
      "        \n",
      "        #fields = line.strip().replace('\"', '').split(\"\\t\") # *OBS* the file \"GSE30272_ExprsMtxCleanedN269_31SVN.txt\" contains a mixture of newlines. I advice not to strip only newlines ('\\n')\n",
      "        fields = line.strip().split(\"\\t\")\n",
      "        probeID = fields[0]\n",
      "        \n",
      "        if probeID in dict_map_probeID2ENSG:\n",
      "            set_probe_mapped.add(probeID)\n",
      "            \n",
      "            ENSG = dict_map_probeID2ENSG[probeID]\n",
      "            \n",
      "            ## metadata\n",
      "            f_row_metadata.write( \"{},{}\\n\".format(ENSG, probeID) )\n",
      "            \n",
      "            ## matrix\n",
      "            #expr_string2write = \",\".join([ENSG]+fields[1:])\n",
      "            #f_expression_matrix.write(expr_string2write + \"\\n\")\n",
      "            f_expression_matrix.write(\",\".join(fields[1:]) + \"\\n\")\n",
      "            for i, field in enumerate(fields[1:]):\n",
      "                if \"HEEBO\" in field: \n",
      "                    #print \"bla\"\n",
      "                    print fields[0:i+3]\n",
      "            #if \"HEEBO\" in line: \n",
      "            #    print \"bla line\"\n",
      "        else:\n",
      "            set_probe_unmapped.add(probeID)\n",
      "            f_row_metadata_unmapped.write( probeID + \"\\n\" )\n",
      "\n",
      "\n",
      "\n",
      "f_row_metadata.close()\n",
      "f_expression_matrix.close()\n",
      "\n",
      "\n",
      "print \"Mapped probes: {}\".format(len(set_probe_mapped))\n",
      "print \"Mapped unprobes: {}\".format(len(set_probe_unmapped))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mapped probes: 23354\n",
        "Mapped unprobes: 6822\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Check expression file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(file_expression_matrix, 'r') as f:\n",
      "    for line in f:\n",
      "        if \"HEEBO\" in line:\n",
      "            print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    1. Read only lines that starts with \"!Sample_\"\n",
      "    2. donor_id --> !Sample_title: \"HB_18_34\"\n",
      "    3. structure_acronym --> !Sample_source_name_ch1\t\"Postmortem dorsolateral prefrontal cortex (DLPFC BA 46/9)\"\n",
      "    4. stage --> DUMMY. Convert later!\n",
      "    4. age --> !Sample_characteristics_ch1\t\"age: -0.498630137\"\n",
      "    5. gender --> !Sample_characteristics_ch1\t\"Sex: F\"\n",
      "    - write out column file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write columns_metadata SKIPPED"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_columns_metadata = \"/Users/pascaltimshel/Dropbox/0_Projects/p_EAv2/data_BrainCloud/processed_data/columns_metadata.csv\"\n",
      "\n",
      "f_columns_metadata = open(file_columns_metadata, 'w')\n",
      "\n",
      "donor_id\n",
      "structure\n",
      "age\n",
      "sex\n",
      "\n",
      "with open(file_series_matrix_sample, 'r') as f_series_matrix_sample:\n",
      "    for line in f_series_matrix_sample:\n",
      "        fields = line.strip(\"\\n\").split(\"\\t\")\n",
      "        rowname = fields\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}